{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b2f7431d",
      "metadata": {},
      "source": [
        "# How to Train RF-DETR Object Detection on a Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a80cff8",
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1710da6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from rfdetr import RFDETRMedium\n",
        "from rfdetr.util.coco_classes import COCO_CLASSES\n",
        "\n",
        "# Custom class names from your trained dataset\n",
        "CUSTOM_CLASSES = ['pen', 'Pen']\n",
        "\n",
        "image = Image.open(\"dataset/valid/00cd18c5aff4548b_jpg.rf.bd1663cdc9106926c3d3507ce963788f.jpg\")\n",
        "\n",
        "model = RFDETRMedium(resolution=640)\n",
        "model.optimize_for_inference()\n",
        "\n",
        "detections = model.predict(image, threshold=0.5)\n",
        "\n",
        "color = sv.ColorPalette.from_hex([\n",
        "    \"#ffff00\", \"#ff9b00\", \"#ff8080\", \"#ff66b2\", \"#ff66ff\", \"#b266ff\",\n",
        "    \"#9999ff\", \"#3399ff\", \"#66ffff\", \"#33ff99\", \"#66ff66\", \"#99ff00\"\n",
        "])\n",
        "text_scale = sv.calculate_optimal_text_scale(resolution_wh=image.size)\n",
        "thickness = sv.calculate_optimal_line_thickness(resolution_wh=image.size)\n",
        "\n",
        "bbox_annotator = sv.BoxAnnotator(color=color, thickness=thickness)\n",
        "label_annotator = sv.LabelAnnotator(\n",
        "    color=color,\n",
        "    text_color=sv.Color.BLACK,\n",
        "    text_scale=text_scale,\n",
        "    smart_position=True\n",
        ")\n",
        "\n",
        "labels = [\n",
        "    f\"{COCO_CLASSES[class_id]} {confidence:.2f}\"\n",
        "    for class_id, confidence\n",
        "    in zip(detections.class_id, detections.confidence)\n",
        "]\n",
        "\n",
        "annotated_image = image.copy()\n",
        "annotated_image = bbox_annotator.annotate(annotated_image, detections)\n",
        "annotated_image = label_annotator.annotate(annotated_image, detections, labels)\n",
        "annotated_image.thumbnail((800, 800))\n",
        "annotated_image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f2d1ba8",
      "metadata": {},
      "source": [
        "```\n",
        "└── dataset\n",
        "    ├── test\n",
        "    │   ├── 0085364b2034b946_jpg.rf.70ae3ded7dadaec0f83fa75a1ca97a1b.jpg\n",
        "    │   ├── 00cd18c5aff4548b_jpg.rf.bd1663cdc9106926c3d3507ce963788f.jpg\n",
        "    │   └── _annotations.coco.json\n",
        "    ├── train\n",
        "    │   ├── 000fcbfa875b9eb2_jpg.rf.2fa47d1e61228c5f856a69c1c51e46ac.jpg\n",
        "    │   ├── 000fcbfa875b9eb2_jpg.rf.3ab8fc8b5e049dad298b5f84e46d12cc.jpg\n",
        "    │   └── _annotations.coco.json\n",
        "    └── valid\n",
        "        ├── 0085364b2034b946_jpg.rf.70ae3ded7dadaec0f83fa75a1ca97a1b.jpg\n",
        "        ├── 00cd18c5aff4548b_jpg.rf.bd1663cdc9106926c3d3507ce963788f.jpg\n",
        "        └── _annotations.coco.json\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44ebabf6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from rfdetr import RFDETRMedium\n",
        "\n",
        "model = RFDETRMedium()\n",
        "\n",
        "model.train(dataset_dir=\"dataset\", epochs=10, batch_size=8, grad_accum_steps=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6899013a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "Image.open(\"output/metrics_plot.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b370489",
      "metadata": {},
      "source": [
        "# Test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c747f5cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "\n",
        "ds = sv.DetectionDataset.from_coco(\n",
        "    images_directory_path=\"dataset/test\",\n",
        "    annotations_path=\"dataset/test/_annotations.coco.json\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ab40a6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "from tqdm import tqdm\n",
        "from supervision.metrics import MeanAveragePrecision\n",
        "\n",
        "targets = []\n",
        "predictions = []\n",
        "\n",
        "for path, image, annotations in tqdm(ds):\n",
        "    image = Image.open(path)\n",
        "    detections = model.predict(image, threshold=0)\n",
        "\n",
        "    targets.append(annotations)\n",
        "    predictions.append(detections)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "871354e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "map_metric = MeanAveragePrecision()\n",
        "map_result = map_metric.update(predictions, targets).compute()\n",
        "print(map_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd8a7f1c",
      "metadata": {},
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84ba20b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = RFDETRMedium(pretrain_weights=\"output/checkpoint_best_total.pth\")\n",
        "model.optimize_for_inference()\n",
        "\n",
        "image = Image.open(\"dataset/valid/00cd18c5aff4548b_jpg.rf.bd1663cdc9106926c3d3507ce963788f.jpg\")\n",
        "\n",
        "detections = model.predict(image, threshold=0.5)\n",
        "\n",
        "print(detections)\n",
        "\n",
        "color = sv.ColorPalette.from_hex([\n",
        "    \"#ffff00\", \"#ff9b00\", \"#ff8080\", \"#ff66b2\", \"#ff66ff\", \"#b266ff\",\n",
        "    \"#9999ff\", \"#3399ff\", \"#66ffff\", \"#33ff99\", \"#66ff66\", \"#99ff00\"\n",
        "])\n",
        "text_scale = sv.calculate_optimal_text_scale(resolution_wh=image.size)\n",
        "thickness = sv.calculate_optimal_line_thickness(resolution_wh=image.size)\n",
        "\n",
        "bbox_annotator = sv.BoxAnnotator(color=color, thickness=thickness)\n",
        "label_annotator = sv.LabelAnnotator(\n",
        "    color=color,\n",
        "    text_color=sv.Color.BLACK,\n",
        "    text_scale=text_scale,\n",
        "    smart_position=True\n",
        ")\n",
        "\n",
        "labels = [\n",
        "    f\"{CUSTOM_CLASSES[class_id]} {confidence:.2f}\"\n",
        "    for class_id, confidence\n",
        "    in zip(detections.class_id, detections.confidence)\n",
        "]\n",
        "\n",
        "annotated_image = image.copy()\n",
        "annotated_image = bbox_annotator.annotate(annotated_image, detections)\n",
        "annotated_image = label_annotator.annotate(annotated_image, detections, labels)\n",
        "annotated_image.thumbnail((800, 800))\n",
        "annotated_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80d0ff90",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "171dc4b1",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
